# 伦理和负责任的 AI

您几乎完成了本课程，我希望到现在您清楚地看到 AI 基于许多形式数学方法，这些方法允许我们在数据中找到关系并训练模型以复制人类行为的某些方面。在历史的这个时刻，我们认为 AI 是一个非常强大的工具，可以从数据中提取模式，并将这些模式应用于解决新问题。

## [课前测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

然而，在科幻小说中，我们经常看到 AI 对人类构成危险的故事。通常这些故事围绕某种 AI 反叛，当 AI 决定对抗人类时。这意味着 AI 有某种情感或可以做出其开发者未预见的决定。

我们在本课程中学到的 AI 类型只不过是大型矩阵算术。它是一个非常强大的工具，可以帮助我们解决问题，就像任何其他强大的工具一样 - 它可以用于好的和坏的目的。重要的是，它可能被*误用*。

## 负责任 AI 的原则

为了避免这种意外或有目的的 AI 误用，Microsoft 阐述了重要的[负责任 AI 原则](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)。以下概念支撑这些原则：

* **公平性**与*模型偏差*的重要问题相关，这可能由使用有偏差的数据进行训练引起。例如，当我们尝试预测一个人获得软件开发工作的概率时，模型可能会给男性更高的偏好 - 仅仅因为训练数据集可能偏向男性受众。我们需要仔细平衡训练数据并调查模型以避免偏差，并确保模型考虑更相关的特征。
* **可靠性和安全性**。就其性质而言，AI 模型可能会犯错误。神经网络返回概率，我们需要在做出决定时考虑这一点。每个模型都有一些精确率和召回率，我们需要理解这一点以防止错误建议可能造成的伤害。
* **隐私和安全**有一些 AI 特定的含义。例如，当我们使用某些数据训练模型时，这些数据以某种方式"整合"到模型中。一方面，这增加了安全性和隐私性，另一方面 - 我们需要记住模型是在哪些数据上训练的。
* **包容性**意味着我们不是在构建 AI 来取代人，而是增强人并使我们的工作更具创造性。它也与公平性相关，因为在处理代表性不足的社区时，我们收集的大多数数据集可能是有偏差的，我们需要确保这些社区被包含并由 AI 正确处理。
* **透明度**。这包括确保我们始终清楚正在使用的 AI。此外，在可能的情况下，我们希望使用*可解释*的 AI 系统。
* **问责制**。当 AI 模型提出某些决定时，并不总是清楚谁对这些决定负责。我们需要确保我们理解 AI 决定的责任所在。在大多数情况下，我们希望将人类纳入重要决策的循环中，以便实际的人承担责任。

## 负责任 AI 的工具

Microsoft 开发了[负责任 AI 工具箱](https://github.com/microsoft/responsible-ai-toolbox)，其中包含一组工具：

* 可解释性仪表板（InterpretML）
* 公平性仪表板（FairLearn）
* 错误分析仪表板
* 负责任 AI 仪表板，包括

   - EconML - 因果分析工具，专注于假设问题
   - DiCE - 反事实分析工具，允许您查看需要更改哪些特征以影响模型的决策

有关 AI 伦理的更多信息，请访问[这节课](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)在包含作业的机器学习课程中。

## 复习与自主学习

参加这个[学习路径](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)以了解更多关于负责任 AI 的信息。

## [课后测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

