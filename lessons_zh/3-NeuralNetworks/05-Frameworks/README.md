# 神经网络框架

正如我们已经学到的，为了能够有效地训练神经网络，我们需要做两件事：

* 对张量进行操作，例如，乘法、加法，并计算一些函数，如 sigmoid 或 softmax
* 计算所有表达式的梯度，以便执行梯度下降优化

## [课前测验](https://ff-quizzes.netlify.app/en/ai/quiz/9)

虽然 `numpy` 库可以完成第一部分，但我们需要某种机制来计算梯度。在[我们的框架](../04-OwnFramework/OwnFramework.ipynb)中，我们在上一节中开发的框架，我们必须在 `backward` 方法中手动编程所有导数函数，该方法执行反向传播。理想情况下，框架应该给我们计算*任何表达式*的梯度的机会。

另一个重要的事情是能够在 GPU 或任何其他专用计算单元（如 [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)）上执行计算。深度神经网络训练需要*大量*计算，能够在 GPU 上并行化这些计算非常重要。

> ✅ 术语"并行化"意味着在多个设备上分布计算。

目前，两个最流行的神经网络框架是：[TensorFlow](http://TensorFlow.org) 和 [PyTorch](https://pytorch.org/)。两者都提供低级 API 来在 CPU 和 GPU 上操作张量。在低级 API 之上，还有更高级的 API，分别称为 [Keras](https://keras.io/) 和 [PyTorch Lightning](https://pytorchlightning.ai/)。

低级 API | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
--------------|-------------------------------------|--------------------------------
高级 API| [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

两个框架中的**低级 API** 允许您构建所谓的**计算图**。此图定义了如何使用给定的输入参数计算输出（通常是损失函数），如果可用，可以推送到 GPU 进行计算。有函数可以区分此计算图并计算梯度，然后可以用于优化模型参数。

**高级 API** 几乎将神经网络视为**层的序列**，并使构建大多数神经网络变得容易得多。训练模型通常需要准备数据，然后调用 `fit` 函数来完成工作。

高级 API 允许您非常快速地构建典型的神经网络，而无需担心很多细节。同时，低级 API 对训练过程提供更多控制，因此它们在研究中被大量使用，当您处理新的神经网络架构时。

同样重要的是要理解您可以同时使用两个 API，例如，您可以使用低级 API 开发自己的网络层架构，然后在用高级 API 构建和训练的更大网络中使用它。或者，您可以使用高级 API 将网络定义为层的序列，然后使用自己的低级训练循环来执行优化。两个 API 使用相同的基本底层概念，它们被设计为很好地协同工作。

## 学习

在本课程中，我们为 PyTorch 和 TensorFlow 提供大部分内容。您可以选择您喜欢的框架，只浏览相应的笔记本。如果您不确定选择哪个框架，请阅读互联网上关于 **PyTorch vs. TensorFlow** 的一些讨论。您也可以查看两个框架以获得更好的理解。

在可能的情况下，我们将使用高级 API 以简化。但是，我们相信从基础开始理解神经网络的工作原理很重要，因此在开始时，我们从使用低级 API 和张量开始。但是，如果您想快速开始并且不想花大量时间学习这些细节，您可以跳过这些，直接进入高级 API 笔记本。

## ✍️ 练习：框架

在以下笔记本中继续学习：

低级 API | [TensorFlow+Keras 笔记本](IntroKerasTF.ipynb) | [PyTorch](IntroPyTorch.ipynb)
--------------|-------------------------------------|--------------------------------
高级 API| [Keras](IntroKeras.ipynb) | *PyTorch Lightning*

掌握框架后，让我们回顾一下过拟合的概念。

# 过拟合

过拟合是机器学习中一个极其重要的概念，正确理解它非常重要！

考虑以下近似 5 个点（在下面的图表中用 `x` 表示）的问题：

![线性](../images/overfit1.jpg) | ![过拟合](../images/overfit2.jpg)
-------------------------|--------------------------
**线性模型，2 个参数** | **非线性模型，7 个参数**
训练误差 = 5.3 | 训练误差 = 0
验证误差 = 5.1 | 验证误差 = 20

* 在左边，我们看到一个良好的直线近似。因为参数数量是合适的，模型正确地理解了点分布背后的思想。
* 在右边，模型太强大了。因为我们只有 5 个点，而模型有 7 个参数，它可以调整以通过所有点，使训练误差为 0。然而，这阻止了模型理解数据背后的正确模式，因此验证误差非常高。

在模型的丰富性（参数数量）和训练样本数量之间取得正确的平衡非常重要。

## 为什么发生过拟合

  * 训练数据不足
  * 模型太强大
  * 输入数据中噪声太多

## 如何检测过拟合

从上面的图表中可以看出，过拟合可以通过非常低的训练误差和高的验证误差来检测。通常在训练期间，我们会看到训练和验证误差都开始减少，然后在某个点验证误差可能停止减少并开始上升。这将是过拟合的迹象，也是我们应该在此点停止训练（或至少对模型进行快照）的指标。

![过拟合](../images/Overfitting.png)

## 如何防止过拟合

如果您可以看到发生过拟合，您可以执行以下操作之一：

 * 增加训练数据量
 * 降低模型的复杂性
 * 使用一些[正则化技术](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md)，如 [Dropout](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout)，我们将在后面考虑。

## 过拟合和偏差-方差权衡

过拟合实际上是统计学中更通用问题的案例，称为 [偏差-方差权衡](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)。如果我们考虑模型中可能的误差来源，我们可以看到两种类型的误差：

* **偏差误差**是由我们的算法无法正确捕获训练数据之间的关系引起的。这可能是因为我们的模型不够强大（**欠拟合**）。
* **方差误差**，是由模型近似输入数据中的噪声而不是有意义的关系引起的（**过拟合**）。

在训练期间，偏差误差减少（因为我们的模型学习近似数据），方差误差增加。重要的是停止训练 - 要么手动（当我们检测到过拟合时）要么自动（通过引入正则化）- 以防止过拟合。

## 结论

在本课中，您了解了两个最流行的 AI 框架 TensorFlow 和 PyTorch 的各种 API 之间的差异。此外，您了解了一个非常重要的主题，过拟合。

## 🚀 挑战

在随附的笔记本中，您会在底部找到"任务"；浏览笔记本并完成任务。

## [课后测验](https://ff-quizzes.netlify.app/en/ai/quiz/10)

## 复习与自主学习

对以下主题进行一些研究：

- TensorFlow
- PyTorch
- 过拟合

问自己以下问题：

- TensorFlow 和 PyTorch 之间有什么区别？
- 过拟合和欠拟合之间有什么区别？

## [作业](lab/README.md)

在这个实验中，要求您使用 PyTorch 或 TensorFlow 使用单层和多层全连接网络解决两个分类问题。

* [说明](lab/README.md)
* [笔记本](lab/LabFrameworks.ipynb)

