# 生成对抗网络

在上一节中，我们了解了**生成模型**：可以生成与训练数据集中相似的图像的模型。VAE 是生成模型的一个很好的例子。

## [课前测验](https://ff-quizzes.netlify.app/en/ai/quiz/19)

但是，如果我们尝试生成真正有意义的东西，比如合理分辨率的绘画，使用 VAE，我们会看到训练不能很好地收敛。对于这个用例，我们应该了解另一种专门针对生成模型的架构 - **生成对抗网络**，或 GAN。

GAN 的主要思想是有两个神经网络将相互对抗训练：

<img src="images/gan_architecture.png" width="70%"/>

> 图片由 [Dmitry Soshnikov](http://soshnikov.com) 制作

> ✅ 一点词汇：
> * **生成器**是一个网络，它接受一些随机向量，并产生图像作为结果
> * **判别器**是一个网络，它接受图像，它应该告诉它是真实图像（来自训练数据集），还是由生成器生成的。它本质上是一个图像分类器。

### 判别器

判别器的架构与普通图像分类网络没有什么不同。在最简单的情况下，它可以是全连接分类器，但最可能的是[卷积网络](../07-ConvNets/README.md)。

> ✅ 基于卷积网络的 GAN 称为 [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

CNN 判别器由以下层组成：几个卷积+池化（空间尺寸减小）和一个或多个全连接层以获得"特征向量"，最终二分类器。

> ✅ 在这种情况下，"池化"是一种减小图像尺寸的技术。"池化层通过将一层中的神经元簇的输出组合到下一层中的单个神经元来减少数据的维度。" - [来源](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 生成器

生成器稍微复杂一些。您可以将其视为反向判别器。从潜在向量开始（代替特征向量），它有一个全连接层将其转换为所需的尺寸/形状，然后是反卷积+上采样。这类似于[自编码器](../09-Autoencoders/README.md)的*解码器*部分。

> ✅ 因为卷积层实现为遍历图像的线性滤波器，反卷积本质上类似于卷积，可以使用相同的层逻辑实现。

<img src="images/gan_arch_detail.png" width="70%"/>

> 图片由 [Dmitry Soshnikov](http://soshnikov.com) 制作

### 训练 GAN

GAN 被称为**对抗**，因为生成器和判别器之间存在持续的竞争。在这种竞争中，生成器和判别器都得到改进，因此网络学会产生越来越好的图片。

训练发生在两个阶段：

* **训练判别器**。这个任务非常简单：我们通过生成器生成一批图像，将它们标记为 0，代表假图像，并从输入数据集中取一批图像（标签为 1，真实图像）。我们获得一些*判别器损失*，并执行反向传播。
* **训练生成器**。这稍微复杂一些，因为我们不知道生成器的预期输出。我们取由生成器和判别器组成的整个 GAN 网络，用一些随机向量馈送它，并期望结果为 1（对应于真实图像）。然后我们冻结判别器的参数（我们不希望它在此步骤中被训练），并执行反向传播。

在这个过程中，生成器和判别器的损失都不会显著下降。在理想情况下，它们应该振荡，对应于两个网络都提高其性能。

## ✍️ 练习：GAN

* [TensorFlow/Keras 中的 GAN 笔记本](GANTF.ipynb)
* [PyTorch 中的 GAN 笔记本](GANPyTorch.ipynb)

### GAN 训练的问题

GAN 以特别难以训练而闻名。以下是一些问题：

* **模式崩溃**。通过这个术语，我们指的是生成器学会产生一个成功的图像来欺骗生成器，而不是各种不同的图像。
* **对超参数的敏感性**。通常您可以看到 GAN 根本不收敛，然后突然降低学习率导致收敛。
* 在生成器和判别器之间保持**平衡**。在许多情况下，判别器损失可以相对快速地降至零，这导致生成器无法进一步训练。为了克服这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低，则跳过判别器训练。
* 训练**高分辨率**。反映了与自编码器相同的问题，这个问题是因为重建太多层卷积网络导致伪影而触发的。这个问题通常通过所谓的**渐进式增长**来解决，当首先在低分辨率图像上训练几层，然后"解锁"或添加层。另一个解决方案是在层之间添加额外连接并同时训练多个分辨率 - 有关详细信息，请参阅此 [多尺度梯度 GAN 论文](https://arxiv.org/abs/1903.06048)。

## 风格迁移

GAN 是生成艺术图像的绝佳方式。另一种有趣的技术是所谓的**风格迁移**，它采用一个**内容图像**，并以不同的风格重新绘制它，应用来自**风格图像**的滤波器。

它的工作方式如下：
* 我们从随机噪声图像开始（或使用内容图像，但为了理解，从随机噪声开始更容易）
* 我们的目标是创建这样的图像，它既接近内容图像又接近风格图像。这将由两个损失函数确定：
   - **内容损失**基于 CNN 在某些层从当前图像和内容图像中提取的特征计算
   - **风格损失**使用 Gram 矩阵以巧妙的方式在当前图像和风格图像之间计算（更多详细信息在[示例笔记本](StyleTransfer.ipynb)中）
* 为了使图像更平滑并去除噪声，我们还引入**变化损失**，它计算相邻像素之间的平均距离
* 主优化循环使用梯度下降（或某些其他优化算法）调整当前图像以最小化总损失，这是所有三个损失的加权和。

## ✍️ 示例：[风格迁移](StyleTransfer.ipynb)

## [课后测验](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## 结论

在本课中，您了解了 GAN 以及如何训练它们。您还了解了这种类型的神经网络可能面临的特殊挑战，以及如何克服它们的一些策略。

## 🚀 挑战

使用您自己的图像运行 [风格迁移笔记本](StyleTransfer.ipynb)。

## 复习与自主学习

作为参考，在这些资源中阅读更多关于 GAN 的内容：

* Marco Pasini，[训练 GAN 一年我学到的 10 课](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)，一个*事实*上要考虑的 GAN 架构
* [在 Azure ML 上使用 GAN 创建生成艺术](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 作业

重新访问与本课相关的两个笔记本之一，并在您自己的图像上重新训练 GAN。您能创建什么？

