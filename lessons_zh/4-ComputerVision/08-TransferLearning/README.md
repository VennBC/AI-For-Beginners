# 预训练网络和迁移学习

训练 CNN 可能需要大量时间，并且需要大量数据来完成该任务。然而，大部分时间都花在学习网络可用于从图像中提取模式的最佳低级滤波器上。一个自然的问题出现了 - 我们能否使用在一个数据集上训练的神经网络，并将其适应为分类不同的图像，而无需完整的训练过程？

## [课前测验](https://ff-quizzes.netlify.app/en/ai/quiz/15)

这种方法称为**迁移学习**，因为我们从一种神经网络模型向另一种模型转移一些知识。在迁移学习中，我们通常从预训练模型开始，该模型已经在某些大型图像数据集（如 **ImageNet**）上进行了训练。这些模型已经可以很好地从通用图像中提取不同的特征，在许多情况下，仅在这些提取的特征之上构建分类器就可以产生良好的结果。

> ✅ 迁移学习是您在其他学术领域（如教育）中发现的术语。它指的是从一个领域获取知识并将其应用于另一个领域的过程。

## 预训练模型作为特征提取器

我们在上一节中讨论的卷积网络包含许多层，每一层都应该从图像中提取一些特征，从低级像素组合（如水平/垂直线或笔划）开始，一直到高级特征组合，对应于像火焰的眼睛这样的东西。如果我们在足够大的通用和多样化图像数据集上训练 CNN，网络应该学会提取那些共同特征。

Keras 和 PyTorch 都包含函数，可以轻松加载某些常见架构的预训练神经网络权重，其中大多数在 ImageNet 图像上进行了训练。最常用的在上一课的 [CNN 架构](../07-ConvNets/CNN_Architectures.md) 页面上描述。特别是，您可能想要考虑使用以下之一：

* **VGG-16/VGG-19** 是相对简单的模型，仍然提供良好的准确率。通常使用 VGG 作为第一次尝试是查看迁移学习如何工作的好选择。
* **ResNet** 是 Microsoft Research 在 2015 年提出的模型系列。它们有更多层，因此需要更多资源。
* **MobileNet** 是一个尺寸减小的模型系列，适用于移动设备。如果您资源不足并且可以牺牲一点准确率，请使用它们。

以下是由 VGG-16 网络从猫的图片中提取的示例特征：

![VGG-16 提取的特征](images/features.png)

## 猫与狗数据集

在此示例中，我们将使用 [猫和狗](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) 的数据集，这非常接近现实生活中的图像分类场景。

## ✍️ 练习：迁移学习

让我们在相应的笔记本中查看迁移学习的实际应用：

* [迁移学习 - PyTorch](TransferLearningPyTorch.ipynb)
* [迁移学习 - TensorFlow](TransferLearningTF.ipynb)

## 可视化对抗猫

预训练的神经网络在其*大脑*内包含不同的模式，包括**理想猫**的概念（以及理想狗、理想斑马等）。以某种方式**可视化这个图像**会很有趣。然而，这并不简单，因为模式分布在网络权重的各处，并且也以分层结构组织。

我们可以采用的一种方法是从一个随机图像开始，然后尝试使用**梯度下降优化**技术来调整该图像，使网络开始认为它是一只猫。

![图像优化循环](images/ideal-cat-loop.png)

但是，如果我们这样做，我们将收到与随机噪声非常相似的东西。这是因为*有很多方法可以让网络认为输入图像是一只猫*，包括一些在视觉上没有意义的方法。虽然这些图像包含很多典型的猫模式，但没有什么可以约束它们在视觉上具有区别性。

为了改善结果，我们可以在损失函数中添加另一个项，称为**变化损失**。它是一个显示图像相邻像素相似程度的指标。最小化变化损失使图像更平滑，并消除噪声 - 从而揭示更具视觉吸引力的模式。以下是这种"理想"图像的示例，它们被高概率分类为猫和斑马：

![理想猫](images/ideal-cat.png) | ![理想斑马](images/ideal-zebra.png)
-----|-----
 *理想猫* | *理想斑马*

类似的方法可用于对神经网络执行所谓的**对抗攻击**。假设我们想欺骗神经网络，让狗看起来像猫。如果我们取狗的图像，它被网络识别为狗，我们可以使用梯度下降优化稍微调整它，直到网络开始将其分类为猫：

![狗的照片](images/original-dog.png) | ![被分类为猫的狗的照片](images/adversarial-dog.png)
-----|-----
*狗的原始照片* | *被分类为猫的狗的照片*

请参阅以下笔记本中的代码以重现上述结果：

* [理想和对抗猫 - TensorFlow](AdversarialCat_TF.ipynb)
## 结论

使用迁移学习，您能够快速为自定义对象分类任务组装分类器并实现高准确率。您可以看到，我们现在解决的更复杂的任务需要更高的计算能力，并且无法在 CPU 上轻松解决。在下一个单元中，我们将尝试使用更轻量级的实现来使用较低的计算资源训练相同的模型，这只会导致稍微较低的准确率。

## 🚀 挑战

在随附的笔记本中，底部有关于迁移知识如何与某种相似的训练数据（可能是新型动物）最有效工作的注释。对完全新型的图像进行一些实验，以查看您的迁移知识模型的表现如何。

## [课后测验](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## 复习与自主学习

阅读 [TrainingTricks.md](TrainingTricks.md) 以加深您对训练模型的其他方法的了解。

## [作业](lab/README.md)

在这个实验中，我们将使用现实生活中的 [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) 宠物数据集，包含 35 种猫和狗，我们将构建一个迁移学习分类器。

