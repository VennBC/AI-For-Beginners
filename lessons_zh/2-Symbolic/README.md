# 知识表示与专家系统

![符号AI内容摘要](../sketchnotes/ai-symbolic.png)



对人工智能的探索基于对知识的搜索，以理解世界，类似于人类的方式。但是您如何做到这一点呢？

## [课前测验](https://ff-quizzes.netlify.app/en/ai/quiz/3)

在 AI 的早期，创建智能系统的自上而下方法（在上一课中讨论）很流行。这个想法是从人们那里提取知识，以某种机器可读的形式，然后使用它来自动解决问题。这种方法基于两个大思想：

* 知识表示
* 推理

## 知识表示

符号 AI 中的重要概念之一是**知识**。区分知识与*信息*或*数据*很重要。例如，可以说书籍包含知识，因为可以学习书籍并成为专家。然而，书籍实际包含的被称为*数据*，通过阅读书籍并将这些数据整合到我们的世界模型中，我们将这些数据转换为知识。

> ✅ **知识**是包含在我们头脑中的东西，代表我们对世界的理解。它是通过主动**学习**过程获得的，该过程将我们接收到的信息片段整合到我们活跃的世界模型中。

大多数情况下，我们不严格定义知识，而是使用 [DIKW 金字塔](https://en.wikipedia.org/wiki/DIKW_pyramid)将其与其他相关概念对齐。它包含以下概念：

* **数据**是以物理媒体表示的东西，例如书面文本或口语单词。数据独立于人类存在，可以在人与人之间传递。
* **信息**是我们在头脑中解释数据的方式。例如，当我们听到*计算机*这个词时，我们对它是什么有一些理解。
* **知识**是整合到我们世界模型中的信息。例如，一旦我们了解了计算机是什么，我们就会开始对它的工作原理、它的成本以及它可以用于什么有一些想法。这个相互关联的概念网络形成了我们的知识。
* **智慧**是我们对世界理解的又一个层次，它代表*元知识*，例如关于如何以及何时应该使用知识的一些概念。

<img src="images/DIKW_Pyramid.png" width="30%"/>

*图片[来自维基百科](https://commons.wikimedia.org/w/index.php?curid=37705247)，由 Longlivetheux - 自己的作品，CC BY-SA 4.0*

因此，**知识表示**的问题是在计算机内以数据形式找到某种有效的方法来表示知识，使其可以自动使用。这可以看作是一个谱系：

![知识表示谱系](images/knowledge-spectrum.png)

> 图片由 [Dmitry Soshnikov](http://soshnikov.com) 制作

* 在左边，有非常简单的知识表示类型，可以被计算机有效使用。最简单的是算法，当知识由计算机程序表示时。然而，这不是表示知识的最佳方式，因为它不灵活。我们头脑中的知识通常是非算法的。
* 在右边，有诸如自然文本的表示。它是最强大的，但不能用于自动推理。

> ✅ 思考一分钟，您如何在头脑中表示知识并将其转换为笔记。是否有特定的格式对您来说有助于记忆？

## 计算机知识表示的分类

我们可以将不同的计算机知识表示方法分为以下几类：

* **网络表示**基于这样一个事实：我们头脑中有一个相互关联的概念网络。我们可以尝试在计算机内将相同的网络再现为图 - 所谓的**语义网络**。

1. **对象-属性-值三元组**或**属性-值对**。由于图可以在计算机内表示为节点和边的列表，我们可以通过包含对象、属性和值的三元组列表来表示语义网络。例如，我们构建以下关于编程语言的三元组：

对象 | 属性 | 值
-------|-----------|------
Python | is | Untyped-Language
Python | invented-by | Guido van Rossum
Python | block-syntax | indentation
Untyped-Language | doesn't have | type definitions

> ✅ 思考三元组如何用于表示其他类型的知识。

2. **层次表示**强调这样一个事实：我们经常在头脑中创建对象的层次结构。例如，我们知道金丝雀是一种鸟，所有鸟都有翅膀。我们也有一些关于金丝雀通常是什么颜色以及它们的飞行速度的想法。

   - **框架表示**基于将每个对象或对象类表示为包含**槽**的**框架**。槽具有可能的默认值、值限制或可以调用的存储过程以获取槽的值。所有框架形成一个类似于面向对象编程语言中对象层次结构的层次结构。
   - **场景**是一种特殊的框架，表示可以随时间展开的复杂情况。

**Python**

槽 | 值 | 默认值 | 区间 |
-----|-------|---------------|----------|
Name | Python | | |
Is-A | Untyped-Language | | |
Variable Case | | CamelCase | |
Program Length | | | 5-5000 lines |
Block Syntax | Indent | | |

3. **过程表示**基于通过可以在某些条件发生时执行的动作列表来表示知识。
   - 产生式规则是 if-then 语句，允许我们得出结论。例如，医生可以有一个规则说**如果**患者发高烧**或**血液检查中 C 反应蛋白水平高**那么**他有炎症。一旦我们遇到其中一个条件，我们就可以得出关于炎症的结论，然后在进一步的推理中使用它。
   - 算法可以被认为是过程表示的另一种形式，尽管它们几乎从未在基于知识的系统中直接使用。

4. **逻辑**最初由亚里士多德提出，作为表示人类通用知识的一种方式。
   - 谓词逻辑作为数学理论太丰富而无法计算，因此通常使用它的某个子集，例如在 Prolog 中使用的 Horn 子句。
   - 描述逻辑是用于表示和推理对象层次结构的逻辑系统家族，分布式知识表示，如*语义网*。

## 专家系统

符号 AI 的早期成功之一是所谓的**专家系统** - 设计用于在某些有限问题领域充当专家的计算机系统。它们基于从一个或多个人类专家中提取的**知识库**，它们包含一个**推理引擎**，在其上执行一些推理。

![人类架构](images/arch-human.png) | ![基于知识的系统](images/arch-kbs.png)
---------------------------------------------|------------------------------------------------
人类神经系统的简化结构 | 基于知识的系统的架构

专家系统的构建类似于人类推理系统，它包含**短期记忆**和**长期记忆**。类似地，在基于知识的系统中，我们区分以下组件：

* **问题记忆**：包含关于当前正在解决的问题的知识，即患者的温度或血压，他是否有炎症等。这种知识也称为**静态知识**，因为它包含我们当前对问题的了解的快照 - 所谓的*问题状态*。
* **知识库**：表示关于问题领域的长期知识。它是从人类专家手动提取的，不会从一次咨询到另一次咨询发生变化。因为它允许我们从一个问题状态导航到另一个问题状态，所以它也称为**动态知识**。
* **推理引擎**：协调在问题状态空间中搜索的整个过程，在必要时向用户提问。它还负责找到要应用于每个状态的正确规则。

作为示例，让我们考虑以下基于其物理特征确定动物的专家系统：

![AND-OR 树](images/AND-OR-Tree.png)

> 图片由 [Dmitry Soshnikov](http://soshnikov.com) 制作

该图称为**AND-OR 树**，它是一组产生式规则的图形表示。在从专家提取知识的开始阶段，绘制树是有用的。为了在计算机内表示知识，使用规则更方便：

```
IF the animal eats meat
OR (animal has sharp teeth
    AND animal has claws
    AND animal has forward-looking eyes
) 
THEN the animal is a carnivore
```

您可以注意到规则左侧的每个条件和动作本质上都是对象-属性-值（OAV）三元组。**工作记忆**包含对应于当前正在解决的问题的 OAV 三元组集合。**规则引擎**查找条件满足的规则并应用它们，将另一个三元组添加到工作记忆中。

> ✅ 在您喜欢的主题上编写您自己的 AND-OR 树！

### 前向推理与后向推理

上述过程称为**前向推理**。它从工作记忆中可用的关于问题的一些初始数据开始，然后执行以下推理循环：

1. 如果目标属性存在于工作记忆中 - 停止并给出结果
2. 查找所有条件当前满足的规则 - 获得规则的**冲突集**。
3. 执行**冲突解决** - 选择将在这一步执行的规则。可能有不同的冲突解决策略：
   - 选择知识库中第一个适用的规则
   - 选择随机规则
   - 选择*更具体*的规则，即满足"左侧"（LHS）中最多条件的规则
4. 应用选定的规则并将新知识插入问题状态
5. 从步骤 1 重复。

然而，在某些情况下，我们可能希望从关于问题的空知识开始，并提出将帮助我们得出结论的问题。例如，在进行医学诊断时，我们通常不会在开始诊断患者之前预先执行所有医学分析。我们更希望在需要做出决定时执行分析。

这个过程可以使用**后向推理**来建模。它由**目标**驱动 - 我们正在寻找的属性值：

1. 选择所有可以给我们目标值的规则（即在 RHS（"右侧"）上有目标的规则）- 冲突集
1. 如果没有此属性的规则，或者有一个规则说我们应该从用户那里询问值 - 询问它，否则：
1. 使用冲突解决策略选择一个我们将用作*假设*的规则 - 我们将尝试证明它
1. 递归地重复规则 LHS 中所有属性的过程，尝试将它们证明为目标
1. 如果在任何时候过程失败 - 在步骤 3 使用另一个规则。

> ✅ 在哪些情况下前向推理更合适？后向推理呢？

### 实现专家系统

专家系统可以使用不同的工具实现：

* 直接在某种高级编程语言中编程它们。这不是最好的想法，因为基于知识的系统的主要优势是知识从推理中分离，并且潜在的问题领域专家应该能够在不理解推理过程细节的情况下编写规则
* 使用**专家系统外壳**，即专门设计用于使用某种知识表示语言填充知识的系统。

## ✍️ 练习：动物推理

请参阅 [Animals.ipynb](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/2-Symbolic/Animals.ipynb) 以了解实现前向和后向推理专家系统的示例。

> **注意**：此示例相当简单，仅给出了专家系统外观的想法。一旦您开始创建这样的系统，您只有在达到一定数量的规则（大约 200+）时才会注意到一些*智能*行为。在某些时候，规则变得太复杂而无法全部记住，此时您可能开始想知道为什么系统会做出某些决定。然而，基于知识的系统的重要特征是，您总是可以*解释*任何决定是如何做出的。

## 本体论和语义网

在 20 世纪末，有一项倡议使用知识表示来注释互联网资源，以便可以找到对应于非常特定查询的资源。这项运动被称为**语义网**，它依赖于几个概念：

- 基于**[描述逻辑](https://en.wikipedia.org/wiki/Description_logic)**（DL）的特殊知识表示。它类似于框架知识表示，因为它构建具有属性的对象层次结构，但它具有形式逻辑语义和推理。有一整个 DL 家族，在表达性和推理的算法复杂性之间取得平衡。
- 分布式知识表示，其中所有概念都由全局 URI 标识符表示，使得可以创建跨越互联网的知识层次结构。
- 用于知识描述的基于 XML 的语言家族：RDF（资源描述框架）、RDFS（RDF 模式）、OWL（本体网络语言）。

语义网中的核心概念是**本体论**的概念。它指的是使用某种形式知识表示对问题领域的明确规范。最简单的本体可以只是问题领域中的对象层次结构，但更复杂的本体将包括可用于推理的规则。

在语义网中，所有表示都基于三元组。每个对象和每个关系都由 URI 唯一标识。例如，如果我们想说明这个 AI 课程是由 Dmitry Soshnikov 在 2022 年 1 月 1 日开发的 - 以下是我们可以使用的三元组：

<img src="images/triplet.png" width="30%"/>

```
http://github.com/microsoft/ai-for-beginners http://www.example.com/terms/creation-date "Jan 13, 2007"
http://github.com/microsoft/ai-for-beginners http://purl.org/dc/elements/1.1/creator http://soshnikov.com
```

> ✅ 这里 `http://www.example.com/terms/creation-date` 和 `http://purl.org/dc/elements/1.1/creator` 是一些众所周知且普遍接受的 URI，用于表达*创建者*和*创建日期*的概念。

在更复杂的情况下，如果我们想定义创建者列表，我们可以使用 RDF 中定义的一些数据结构。

<img src="images/triplet-complex.png" width="40%"/>

> 上图由 [Dmitry Soshnikov](http://soshnikov.com) 制作

构建语义网的进展在某种程度上被搜索引擎和自然语言处理技术的成功所减缓，这些技术允许从文本中提取结构化数据。然而，在某些领域，仍然有大量努力来维护本体和知识库。一些值得注意的项目：

* [WikiData](https://wikidata.org/) 是与 Wikipedia 关联的机器可读知识库集合。大多数数据是从 Wikipedia *信息框*中挖掘的，这是 Wikipedia 页面内的结构化内容片段。您可以在 SPARQL（语义网的特殊查询语言）中[查询](https://query.wikidata.org/) wikidata。以下是一个示例查询，显示人类中最受欢迎的眼睛颜色：

```sparql
#defaultView:BubbleChart
SELECT ?eyeColorLabel (COUNT(?human) AS ?count)
WHERE
{
  ?human wdt:P31 wd:Q5.       # human instance-of homo sapiens
  ?human wdt:P1340 ?eyeColor. # human eye-color ?eyeColor
  SERVICE wikibase:label { bd:serviceParam wikibase:language "en". }
}
GROUP BY ?eyeColorLabel
```

* [DBpedia](https://www.dbpedia.org/) 是另一个类似于 WikiData 的努力。

> ✅ 如果您想尝试构建自己的本体，或打开现有的本体，有一个很棒的视觉本体编辑器称为 [Protégé](https://protege.stanford.edu/)。下载它，或在线使用它。

<img src="images/protege.png" width="70%"/>

*Web Protégé 编辑器打开，显示罗曼诺夫家族本体。截图由 Dmitry Soshnikov 提供*

## ✍️ 练习：家族本体

请参阅 [FamilyOntology.ipynb](https://github.com/Ezana135/AI-For-Beginners/blob/main/lessons/2-Symbolic/FamilyOntology.ipynb) 以了解使用语义网技术推理家族关系的示例。我们将采用以常见 GEDCOM 格式表示的家族树和家族关系本体，并为给定的一组个人构建所有家族关系的图。

## Microsoft 概念图

在大多数情况下，本体是手工精心创建的。然而，也可以从非结构化数据中**挖掘**本体，例如，从自然语言文本中。

Microsoft Research 进行了这样一次尝试，并产生了 [Microsoft 概念图](https://blogs.microsoft.com/ai/microsoft-researchers-release-graph-that-helps-machines-conceptualize/?WT.mc_id=academic-77998-cacaste)。

它是使用 `is-a` 继承关系分组在一起的大量实体集合。它允许回答诸如"Microsoft 是什么？"这样的问题 - 答案是"一家公司，概率为 0.87，一个品牌，概率为 0.75"。

该图可以作为 REST API 使用，或作为列出所有实体对的大型可下载文本文件。

## ✍️ 练习：概念图

尝试 [MSConceptGraph.ipynb](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/2-Symbolic/MSConceptGraph.ipynb) 笔记本，看看我们如何使用 Microsoft 概念图将新闻文章分组到几个类别中。

## 结论

如今，AI 通常被认为是*机器学习*或*神经网络*的同义词。然而，人类也表现出明确的推理，这是目前神经网络无法处理的。在现实世界的项目中，明确的推理仍然用于执行需要解释的任务，或者能够以受控方式修改系统行为。

## 🚀 挑战

在与本课程相关的家族本体笔记本中，有机会尝试其他家族关系。尝试发现家族树中人们之间的新联系。

## [课后测验](https://ff-quizzes.netlify.app/en/ai/quiz/4)

## 复习与自主学习

在互联网上进行一些研究，以发现人类试图量化和编码知识的领域。看看布鲁姆分类法，回到历史中了解人类如何试图理解他们的世界。探索林奈的工作以创建生物分类法，并观察门捷列夫创建描述和分组化学元素的方式。您还能找到其他有趣的例子吗？

**作业**：[构建本体](assignment.md)

